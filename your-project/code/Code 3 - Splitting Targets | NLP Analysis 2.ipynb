{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(r'../data/personalities_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2['I-E'] = data2['type'].astype(str).str[0]\n",
    "data2['N-S'] = data2['type'].astype(str).str[1]\n",
    "data2['T-F'] = data2['type'].astype(str).str[2]\n",
    "data2['J-P'] = data2['type'].astype(str).str[3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data2.drop(columns=['Unnamed: 0', 'posts', 'text_processed'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type          0\n",
       "text_ready    1\n",
       "I-E           0\n",
       "N-S           0\n",
       "T-F           0\n",
       "J-P           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text_ready</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3559</th>\n",
       "      <td>INFP</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type text_ready I-E N-S T-F J-P\n",
       "3559  INFP        NaN   I   N   F   P"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = data2[data2.isna().any(axis=1)]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.drop(data2.index[3559], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type          0\n",
       "text_ready    0\n",
       "I-E           0\n",
       "N-S           0\n",
       "T-F           0\n",
       "J-P           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>text_ready</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>intj moment sportscent top ten play prank ha l...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>find lack post veri alarm sex bore posit often...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>good one cours say know bless cur doe absolut ...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>dear intp enjoy convers day esoter gab natur u...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                         text_ready I-E N-S T-F J-P\n",
       "0  INFJ  intj moment sportscent top ten play prank ha l...   I   N   F   J\n",
       "1  ENTP  find lack post veri alarm sex bore posit often...   E   N   T   P\n",
       "2  INTP  good one cours say know bless cur doe absolut ...   I   N   T   P\n",
       "3  INTJ  dear intp enjoy convers day esoter gab natur u...   I   N   T   J\n",
       "4  ENTJ  fire anoth silli misconcept approach logic go ...   E   N   T   J"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining learnings for each \n",
    "x = data2['text_ready']\n",
    "\n",
    "y_IE = data2['I-E']\n",
    "y_NS = data2['N-S']\n",
    "y_TF = data2['T-F']\n",
    "y_JP = data2['J-P']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for vector functions\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(ngram_range=(2, 2)).fit(x) \n",
    "X = vector.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "svd = TruncatedSVD(n_components = 100)\n",
    "reduced = svd.fit_transform(X)\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled = scaler.fit_transform(reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimizing Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "I    6675\n",
       "E    1999\n",
       "Name: I-E, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_IE.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E Accuracy for  1  neigbours.\n",
      "Label I-E test score is : 0.7636887608069164\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   1  410]\n",
      " [   0 1324]]\n",
      "I-E Accuracy for  3  neigbours.\n",
      "Label I-E test score is : 0.768299711815562\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   1  400]\n",
      " [   2 1332]]\n",
      "I-E Accuracy for  5  neigbours.\n",
      "Label I-E test score is : 0.7648414985590778\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   0  408]\n",
      " [   0 1327]]\n",
      "I-E Accuracy for  7  neigbours.\n",
      "Label I-E test score is : 0.7769452449567723\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   0  385]\n",
      " [   2 1348]]\n",
      "I-E Accuracy for  9  neigbours.\n",
      "Label I-E test score is : 0.7711815561959654\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   0  397]\n",
      " [   0 1338]]\n",
      "I-E Accuracy for  11  neigbours.\n",
      "Label I-E test score is : 0.7757925072046109\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   0  389]\n",
      " [   0 1346]]\n",
      "I-E Accuracy for  13  neigbours.\n",
      "Label I-E test score is : 0.7694524495677233\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   0  400]\n",
      " [   0 1335]]\n",
      "I-E Accuracy for  15  neigbours.\n",
      "Label I-E test score is : 0.7769452449567723\n",
      "Confusion Matrix for KNeighbors:\n",
      "[[   0  387]\n",
      " [   0 1348]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "for x in range(1, 16, 2):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2)\n",
    "    knn = KNeighborsClassifier(n_neighbors = x)\n",
    "    clf = knn.fit(x_train, y_train)\n",
    "    predknn = clf.predict(x_test)\n",
    "    print(\"I-E Accuracy for \", x, \" neigbours.\")\n",
    "    print('Label I-E test score is :',accuracy_score(y_test, predknn))\n",
    "    print(\"Confusion Matrix for KNeighbors:\")\n",
    "    print(confusion_matrix(y_test, predknn))\n",
    "    #print(\"Score:\",round(accuracy_score(predknn, y_test)*100,2))\n",
    "\n",
    "#print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E Accuracy for  1  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  2  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  3  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  4  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  5  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  6  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  7  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  8  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  9  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  10  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  11  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  12  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  13  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  14  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "I-E Accuracy for  15  max_depth.\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "for x in range(1, 16):\n",
    "    rfn = RandomForestClassifier(max_depth= x, random_state=0)\n",
    "\n",
    "    # NS\n",
    "    x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "    rfn.fit(x_train, y_train)\n",
    "#    ieb_train = knn.score(x_train,y_train)\n",
    "#    ieb_test = knn.score (x_train,y_train)\n",
    "    predrfn = rfn.predict(x_test)\n",
    "    print(\"I-E Accuracy for \", x, \" max_depth.\")\n",
    "#    print('Label I-E train score is :',ieb_train)\n",
    "    print(confusion_matrix(y_test,predrfn))\n",
    "    print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "    #print(\"Score:\",round(accuracy_score(predknn, y_test)*100,2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Negative values in data passed to MultinomialNB (input X)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-ec2a5a078212>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# IE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_IE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mieb_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mieb_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_counters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_effective_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_alpha\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_feature_log_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36m_count\u001b[0;34m(self, X, Y)\u001b[0m\n\u001b[1;32m    754\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[0;34m\"\"\"Count and smooth feature occurrences.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 756\u001b[0;31m         \u001b[0mcheck_non_negative\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MultinomialNB (input X)\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    757\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_count_\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_non_negative\u001b[0;34m(X, whom)\u001b[0m\n\u001b[1;32m    992\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_min\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Negative values in data passed to %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mwhom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Negative values in data passed to MultinomialNB (input X)"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "ieb_train = mnb.score (x_train,y_train)\n",
    "ieb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "nsb_train = mnb.score (x_train,y_train)\n",
    "nsb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_TF, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "tfb_train = mnb.score (x_train,y_train)\n",
    "tfb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_JP, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "jpb_train = mnb.score (x_train,y_train)\n",
    "jpb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 1.0\n",
      "Label I-E test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[ 91 302]\n",
      " [353 989]]\n",
      "Score: 62.25\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.20      0.23      0.22       393\n",
      "           I       0.77      0.74      0.75      1342\n",
      "\n",
      "    accuracy                           0.62      1735\n",
      "   macro avg       0.49      0.48      0.48      1735\n",
      "weighted avg       0.64      0.62      0.63      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "N-S RESULTS\n",
      "Label N-S train score is : 1.0\n",
      "Label N-S test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[1260  237]\n",
      " [ 186   52]]\n",
      "Score: 75.62\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.87      0.84      0.86      1497\n",
      "           S       0.18      0.22      0.20       238\n",
      "\n",
      "    accuracy                           0.76      1735\n",
      "   macro avg       0.53      0.53      0.53      1735\n",
      "weighted avg       0.78      0.76      0.77      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "T-F Results\n",
      "Label T-F train score is : 1.0\n",
      "Label T-F test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[583 377]\n",
      " [359 416]]\n",
      "Score: 57.58\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.62      0.61      0.61       960\n",
      "           T       0.52      0.54      0.53       775\n",
      "\n",
      "    accuracy                           0.58      1735\n",
      "   macro avg       0.57      0.57      0.57      1735\n",
      "weighted avg       0.58      0.58      0.58      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 1.0\n",
      "Label J-P test score is : 1.0\n",
      "Confusion Matrix for Decision Tree:\n",
      "[[304 376]\n",
      " [418 637]]\n",
      "Score: 54.24\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.42      0.45      0.43       680\n",
      "           P       0.63      0.60      0.62      1055\n",
      "\n",
      "    accuracy                           0.54      1735\n",
      "   macro avg       0.52      0.53      0.52      1735\n",
      "weighted avg       0.55      0.54      0.54      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "ieb_train = dt.score (x_train,y_train)\n",
    "ieb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "nsb_train = dt.score (x_train,y_train)\n",
    "nsb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_TF, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "tfb_train = dt.score (x_train,y_train)\n",
    "tfb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_JP, test_size=0.2, random_state=10)\n",
    "dt.fit(x_train, y_train)\n",
    "jpb_train = dt.score (x_train,y_train)\n",
    "jpb_test = dt.score (x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K Nearest Neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 0.7867127828217323\n",
      "Label I-E test score is : 0.7867127828217323\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[  39  354]\n",
      " [  58 1284]]\n",
      "Score: 76.25\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.40      0.10      0.16       393\n",
      "           I       0.78      0.96      0.86      1342\n",
      "\n",
      "    accuracy                           0.76      1735\n",
      "   macro avg       0.59      0.53      0.51      1735\n",
      "weighted avg       0.70      0.76      0.70      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "N-S RESULTS\n",
      "Label N-S train score is : 0.8648220204640438\n",
      "Label N-S test score is : 0.8648220204640438\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[1475   22]\n",
      " [ 233    5]]\n",
      "Score: 85.3\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      0.99      0.92      1497\n",
      "           S       0.19      0.02      0.04       238\n",
      "\n",
      "    accuracy                           0.85      1735\n",
      "   macro avg       0.52      0.50      0.48      1735\n",
      "weighted avg       0.77      0.85      0.80      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "T-F Results\n",
      "Label T-F train score is : 0.7122063697939184\n",
      "Label T-F test score is : 0.7122063697939184\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[509 451]\n",
      " [282 493]]\n",
      "Score: 57.75\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.64      0.53      0.58       960\n",
      "           T       0.52      0.64      0.57       775\n",
      "\n",
      "    accuracy                           0.58      1735\n",
      "   macro avg       0.58      0.58      0.58      1735\n",
      "weighted avg       0.59      0.58      0.58      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 0.6921746649373108\n",
      "Label J-P test score is : 0.6921746649373108\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[196 484]\n",
      " [282 773]]\n",
      "Score: 55.85\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.41      0.29      0.34       680\n",
      "           P       0.61      0.73      0.67      1055\n",
      "\n",
      "    accuracy                           0.56      1735\n",
      "   macro avg       0.51      0.51      0.50      1735\n",
      "weighted avg       0.53      0.56      0.54      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "ieb_train = knn.score (x_train,y_train)\n",
    "ieb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "nsb_train = knn.score (x_train,y_train)\n",
    "nsb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_TF, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "tfb_train = knn.score (x_train,y_train)\n",
    "tfb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_JP, test_size=0.2, random_state=10)\n",
    "knn.fit(x_train, y_train)\n",
    "jpb_train = knn.score (x_train,y_train)\n",
    "jpb_test = knn.score (x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predknn))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I-E RESULTS\n",
      "Label I-E train score is : 0.769275111687563\n",
      "Label I-E test score is : 0.769275111687563\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[   0  393]\n",
      " [   0 1342]]\n",
      "Score: 77.35\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           E       0.00      0.00      0.00       393\n",
      "           I       0.77      1.00      0.87      1342\n",
      "\n",
      "    accuracy                           0.77      1735\n",
      "   macro avg       0.39      0.50      0.44      1735\n",
      "weighted avg       0.60      0.77      0.67      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N-S RESULTS\n",
      "Label N-S train score is : 0.8622279867416054\n",
      "Label N-S test score is : 0.8622279867416054\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[1497    0]\n",
      " [ 238    0]]\n",
      "Score: 86.28\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           N       0.86      1.00      0.93      1497\n",
      "           S       0.00      0.00      0.00       238\n",
      "\n",
      "    accuracy                           0.86      1735\n",
      "   macro avg       0.43      0.50      0.46      1735\n",
      "weighted avg       0.74      0.86      0.80      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T-F Results\n",
      "Label T-F train score is : 0.7238795215448912\n",
      "Label T-F test score is : 0.7238795215448912\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[726 234]\n",
      " [361 414]]\n",
      "Score: 65.71\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           F       0.67      0.76      0.71       960\n",
      "           T       0.64      0.53      0.58       775\n",
      "\n",
      "    accuracy                           0.66      1735\n",
      "   macro avg       0.65      0.65      0.65      1735\n",
      "weighted avg       0.65      0.66      0.65      1735\n",
      "\n",
      "****************************************************************************************************\n",
      "J-P Results\n",
      "Label J-P train score is : 0.6235768842772734\n",
      "Label J-P test score is : 0.6235768842772734\n",
      "Confusion Matrix for Multinomial Naive Bayes:\n",
      "[[   9  671]\n",
      " [   3 1052]]\n",
      "Score: 61.15\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           J       0.75      0.01      0.03       680\n",
      "           P       0.61      1.00      0.76      1055\n",
      "\n",
      "    accuracy                           0.61      1735\n",
      "   macro avg       0.68      0.51      0.39      1735\n",
      "weighted avg       0.67      0.61      0.47      1735\n",
      "\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfn = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "rfn.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_IE, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "ieb_train = rfn.score (x_train,y_train)\n",
    "ieb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_NS, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "nsb_train = rfn.score (x_train,y_train)\n",
    "nsb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_TF, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "tfb_train = rfn.score (x_train,y_train)\n",
    "tfb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(reduced, y_JP, test_size=0.2, random_state=10)\n",
    "rfn.fit(x_train, y_train)\n",
    "jpb_train = rfn.score (x_train,y_train)\n",
    "jpb_test = rfn.score (x_train,y_train)\n",
    "predrfn = rfn.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predrfn))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrfn)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrfn))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import re\n",
    "\n",
    "import keras\n",
    "from keras import models\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.keras.models import load_model\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>text_processed</th>\n",
       "      <th>text_ready</th>\n",
       "      <th>I-E</th>\n",
       "      <th>N-S</th>\n",
       "      <th>T-F</th>\n",
       "      <th>J-P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "      <td>['intj', 'moment', 'sportscent', 'top', 'ten',...</td>\n",
       "      <td>intj moment sportscent top ten play prank ha l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "      <td>['find', 'lack', 'post', 'veri', 'alarm', 'sex...</td>\n",
       "      <td>find lack post veri alarm sex bore posit often...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "      <td>['good', 'one', 'cours', 'say', 'know', 'bless...</td>\n",
       "      <td>good one cours say know bless cur doe absolut ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "      <td>['dear', 'intp', 'enjoy', 'convers', 'day', 'e...</td>\n",
       "      <td>dear intp enjoy convers day esoter gab natur u...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "      <td>['fire', 'anoth', 'silli', 'misconcept', 'appr...</td>\n",
       "      <td>fire anoth silli misconcept approach logic go ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  type                                              posts  \\\n",
       "0           0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
       "1           1  ENTP  'I'm finding the lack of me in these posts ver...   \n",
       "2           2  INTP  'Good one  _____   https://www.youtube.com/wat...   \n",
       "3           3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   \n",
       "4           4  ENTJ  'You're fired.|||That's another silly misconce...   \n",
       "\n",
       "                                      text_processed  \\\n",
       "0  ['intj', 'moment', 'sportscent', 'top', 'ten',...   \n",
       "1  ['find', 'lack', 'post', 'veri', 'alarm', 'sex...   \n",
       "2  ['good', 'one', 'cours', 'say', 'know', 'bless...   \n",
       "3  ['dear', 'intp', 'enjoy', 'convers', 'day', 'e...   \n",
       "4  ['fire', 'anoth', 'silli', 'misconcept', 'appr...   \n",
       "\n",
       "                                          text_ready  I-E  N-S  T-F  J-P  \n",
       "0  intj moment sportscent top ten play prank ha l...    0    0    1    0  \n",
       "1  find lack post veri alarm sex bore posit often...    1    0    0    1  \n",
       "2  good one cours say know bless cur doe absolut ...    0    0    0    1  \n",
       "3  dear intp enjoy convers day esoter gab natur u...    0    0    0    0  \n",
       "4  fire anoth silli misconcept approach logic go ...    1    0    0    0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_neural = data.copy()\n",
    "\n",
    "data_neural['I-E'] = data_neural['I-E'].astype('category')\n",
    "data_neural['N-S'] = data_neural['N-S'].astype('category')\n",
    "data_neural['T-F'] = data_neural['T-F'].astype('category')\n",
    "data_neural['J-P'] = data_neural['J-P'].astype('category')\n",
    "\n",
    "cat_columns = data_neural.select_dtypes(['category']).columns\n",
    "\n",
    "data_neural[cat_columns] = data_neural[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "data_neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = data_neural['text_ready']\n",
    "\n",
    "y_IE = data_neural['I-E']\n",
    "y_NS = data_neural['N-S']\n",
    "y_TF = data_neural['T-F']\n",
    "y_JP = data_neural['J-P']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vector = CountVectorizer(ngram_range=(2, 2)).fit(x) \n",
    "X = vector.transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Dense(units=256, kernel_initializer='uniform', activation='relu', input_dim=1986297))\n",
    "model.add(tf.keras.layers.Dense(units=128, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(units=64, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(activation = 'sigmoid', units = 1, kernel_initializer = 'uniform')) # output layer has number of outputs not number of neurons\n",
    "\n",
    "model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "# calculating loss, model is always trying to minimize loss, adam is the default optimize\n",
    "\n",
    "\n",
    "# model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "\n",
    "# val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "# print(f'Test loss: {val_loss}')\n",
    "# print(f'Test accuracy: {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Keras is training/fitting/evaluating on array-like data. Keras may not be optimized for this format, so if your input data format is supported by TensorFlow I/O (https://github.com/tensorflow/io) we recommend using that to load a Dataset instead.\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": " TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 241, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 130, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 512, in slice_array\n    contiguous=contiguous)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in slice_arrays\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1799]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-a0e8df9636ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# IE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_IE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"I-E RESULTS\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m:  TypeError: 'SparseTensor' object is not subscriptable\nTraceback (most recent call last):\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 241, in __call__\n    return func(device, token, args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/ops/script_ops.py\", line 130, in __call__\n    ret = self._func(*args)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/autograph/impl/api.py\", line 309, in wrapper\n    return func(*args, **kwargs)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in py_method\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 513, in <listcomp>\n    return [slice_array(inp) for inp in flat_inputs]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 512, in slice_array\n    contiguous=contiguous)\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in slice_arrays\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\n  File \"/usr/local/Cellar/jupyterlab/1.2.4/libexec/lib/python3.7/site-packages/tensorflow/python/keras/engine/training_utils.py\", line 391, in <listcomp>\n    entries = [[x[i:i + 1] for i in indices] for x in arrays]\n\nTypeError: 'SparseTensor' object is not subscriptable\n\n\n\t [[{{node EagerPyFunc}}]]\n\t [[IteratorGetNext]] [Op:__inference_train_function_1799]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# IE\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_IE, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_NS, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_TF, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_JP, test_size=0.2, random_state=10)\n",
    "model.fit(X_train, y_train, epochs = 10, batch_size= 25)\n",
    "predmodel = model.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "# print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "# print(confusion_matrix(y_test,predmodel))\n",
    "# print(\"Score:\",round(accuracy_score(y_test,predmodel)*100,2))\n",
    "# print(\"Classification Report:\",classification_report(y_test,predmodel))\n",
    "val_loss, val_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test loss: {val_loss}')\n",
    "print(f'Test accuracy: {val_acc}')\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "# IE\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_IE, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "ieb_train = mnb.score (x_train,y_train)\n",
    "ieb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"I-E RESULTS\")\n",
    "print('Label I-E train score is :',ieb_train)\n",
    "print('Label I-E test score is :',ieb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# NS\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_NS, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "nsb_train = mnb.score (x_train,y_train)\n",
    "nsb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"N-S RESULTS\")\n",
    "print('Label N-S train score is :',nsb_train)\n",
    "print('Label N-S test score is :',nsb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# TF\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_TF, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "tfb_train = mnb.score (x_train,y_train)\n",
    "tfb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"T-F Results\")\n",
    "print('Label T-F train score is :',tfb_train)\n",
    "print('Label T-F test score is :',tfb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)\n",
    "\n",
    "# JP\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y_JP, test_size=0.2, random_state=10)\n",
    "mnb.fit(x_train, y_train)\n",
    "jpb_train = mnb.score (x_train,y_train)\n",
    "jpb_test = mnb.score (x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"J-P Results\")\n",
    "print('Label J-P train score is :',jpb_train)\n",
    "print('Label J-P test score is :',jpb_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))\n",
    "print(\"*\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
